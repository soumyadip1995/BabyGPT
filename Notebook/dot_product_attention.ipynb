{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/text.txt', 'r').read().split()\n",
        "words[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3iL7zQWCmdW",
        "outputId": "2d980df7-87e2-433c-8052-7a13cffdad8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['So',\n",
              " 'Ray',\n",
              " 'J',\n",
              " 'went',\n",
              " 'straight',\n",
              " 'to',\n",
              " 'the',\n",
              " 'radio',\n",
              " 'station',\n",
              " 'The',\n",
              " 'very',\n",
              " 'next',\n",
              " 'day,',\n",
              " '\"Hey',\n",
              " 'Fab,',\n",
              " \"I'ma\",\n",
              " 'kill',\n",
              " 'you!\"',\n",
              " 'Lyrics',\n",
              " \"comin'\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from karpathy\n",
        "# create a bigram by sliding across 2 words at a time\n",
        "data = {}\n",
        "for w in words:\n",
        "  chars = list(w)\n",
        "  for ch1, ch2 in zip(chars, chars[2:]):\n",
        "    bigram = (ch1, ch2)\n",
        "    data[bigram] = data.get(bigram, 0) + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "K5iG857vD4RG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(data.items(), key = lambda kv: -kv[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyqmGYeKEguO",
        "outputId": "9a287a8e-4b34-4732-8543-948368874739"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('t', 'e'), 11),\n",
              " (('a', 'i'), 9),\n",
              " (('i', 'g'), 9),\n",
              " (('t', 'a'), 7),\n",
              " (('i', \"'\"), 7),\n",
              " (('h', 't'), 7),\n",
              " (('a', 'e'), 7),\n",
              " (('t', 'n'), 7),\n",
              " (('y', 'u'), 6),\n",
              " (('u', 'e'), 6),\n",
              " (('a', 'd'), 6),\n",
              " (('e', 'e'), 6),\n",
              " (('g', 't'), 5),\n",
              " (('I', 'm'), 5),\n",
              " (('m', 'n'), 5),\n",
              " (('v', 't'), 5),\n",
              " (('e', 'l'), 5),\n",
              " (('h', 'y'), 5),\n",
              " (('v', 'r'), 4),\n",
              " (('u', 'i'), 4),\n",
              " (('n', 't'), 4),\n",
              " (('o', 'e'), 4),\n",
              " (('t', 's'), 4),\n",
              " (('s', 'r'), 3),\n",
              " (('i', 'h'), 3),\n",
              " (('t', 't'), 3),\n",
              " ((\"'\", 'a'), 3),\n",
              " (('r', 'c'), 3),\n",
              " (('o', 'i'), 3),\n",
              " (('e', 's'), 3),\n",
              " (('u', 'm'), 3),\n",
              " (('m', 'a'), 3),\n",
              " (('m', ','), 3),\n",
              " (('a', 's'), 3),\n",
              " (('t', 'r'), 3),\n",
              " (('r', 'u'), 3),\n",
              " (('i', 'e'), 3),\n",
              " (('h', 'n'), 3),\n",
              " (('e', 'i'), 3),\n",
              " (('o', 'f'), 3),\n",
              " (('e', 'a'), 3),\n",
              " (('l', 'v'), 3),\n",
              " (('m', 'k'), 3),\n",
              " (('e', 't'), 2),\n",
              " (('d', 'o'), 2),\n",
              " (('s', 'a'), 2),\n",
              " (('t', 'o'), 2),\n",
              " (('i', 'n'), 2),\n",
              " (('d', 'y'), 2),\n",
              " (('a', ','), 2),\n",
              " (('i', 's'), 2),\n",
              " (('s', 'p'), 2),\n",
              " (('p', 'r'), 2),\n",
              " (('s', 'm'), 2),\n",
              " (('m', '-'), 2),\n",
              " (('a', 'l'), 2),\n",
              " (('-', 'u'), 2),\n",
              " (('l', 'm'), 2),\n",
              " (('o', 'a'), 2),\n",
              " (('h', 'm'), 2),\n",
              " (('u', 'a'), 2),\n",
              " (('h', 'o'), 2),\n",
              " (('t', 'v'), 2),\n",
              " (('Y', 'u'), 2),\n",
              " (('s', 'y'), 2),\n",
              " (('o', 'h'), 2),\n",
              " ((\"'\", 'l'), 2),\n",
              " (('a', 't'), 2),\n",
              " (('n', ','), 2),\n",
              " (('o', 's'), 2),\n",
              " (('r', 't'), 2),\n",
              " (('m', 't'), 2),\n",
              " (('e', 'f'), 2),\n",
              " (('i', 'a'), 2),\n",
              " (('k', 'o'), 2),\n",
              " (('n', 'w'), 2),\n",
              " (('c', 'n'), 2),\n",
              " (('w', 'y'), 2),\n",
              " ((\"'\", 'm'), 2),\n",
              " (('m', 's'), 2),\n",
              " (('s', 'c'), 2),\n",
              " (('a', 'o'), 2),\n",
              " (('f', 's'), 2),\n",
              " (('h', 'p'), 2),\n",
              " (('o', ','), 2),\n",
              " (('o', 'k'), 2),\n",
              " (('R', 'y'), 1),\n",
              " (('w', 'n'), 1),\n",
              " (('r', 'i'), 1),\n",
              " (('a', 'g'), 1),\n",
              " (('r', 'd'), 1),\n",
              " (('T', 'e'), 1),\n",
              " (('e', 'y'), 1),\n",
              " (('n', 'x'), 1),\n",
              " (('\"', 'e'), 1),\n",
              " (('H', 'y'), 1),\n",
              " (('F', 'b'), 1),\n",
              " (('k', 'l'), 1),\n",
              " (('i', 'l'), 1),\n",
              " (('o', '!'), 1),\n",
              " (('u', '\"'), 1),\n",
              " (('L', 'r'), 1),\n",
              " (('y', 'i'), 1),\n",
              " (('c', 'm'), 1),\n",
              " (('r', 'o'), 1),\n",
              " (('s', 'n'), 1),\n",
              " (('n', 'c'), 1),\n",
              " (('s', 'e'), 1),\n",
              " (('p', 'e'), 1),\n",
              " (('e', 'd'), 1),\n",
              " (('(', '.'), 1),\n",
              " (('J', 'J'), 1),\n",
              " (('.', '.'), 1),\n",
              " (('F', 'd'), 1),\n",
              " (('a', ')'), 1),\n",
              " (('U', ','), 1),\n",
              " (('o', 'm'), 1),\n",
              " (('s', 'u'), 1),\n",
              " (('W', 'a'), 1),\n",
              " (('o', 't'), 1),\n",
              " (('o', 'g'), 1),\n",
              " (('u', 'h'), 1),\n",
              " (('e', 'h'), 1),\n",
              " (('a', '?'), 1),\n",
              " (('I', 'n'), 1),\n",
              " (('n', 'o'), 1),\n",
              " (('n', 'v'), 1),\n",
              " (('m', 'd'), 1),\n",
              " (('r', 'b'), 1),\n",
              " (('u', 'b'), 1),\n",
              " (('b', 'e'), 1),\n",
              " (('b', 'r'), 1),\n",
              " (('a', 'y'), 1),\n",
              " (('y', 'h'), 1),\n",
              " (('t', 'i'), 1),\n",
              " (('i', 'o'), 1),\n",
              " (('c', 'c'), 1),\n",
              " (('c', 'e'), 1),\n",
              " (('t', 'l'), 1),\n",
              " (('g', 'u'), 1),\n",
              " (('l', 'e'), 1),\n",
              " (('d', 'v'), 1),\n",
              " (('v', 's'), 1),\n",
              " (('m', 'r'), 1),\n",
              " (('d', 'm'), 1),\n",
              " (('e', 'o'), 1),\n",
              " (('H', 'w'), 1),\n",
              " (('g', 'v'), 1),\n",
              " (('h', 'r'), 1),\n",
              " (('f', 'c'), 1),\n",
              " (('u', 'k'), 1),\n",
              " (('c', 'i'), 1),\n",
              " (('k', 'n'), 1),\n",
              " (('d', 'e'), 1),\n",
              " (('e', 'c'), 1),\n",
              " (('n', 'e'), 1),\n",
              " (('f', 'e'), 1),\n",
              " (('l', 'n'), 1),\n",
              " (('l', 'k'), 1),\n",
              " (('N', 'v'), 1),\n",
              " (('f', 'd'), 1),\n",
              " (('d', 'n'), 1),\n",
              " (('f', 'r'), 1),\n",
              " (('r', 'v'), 1),\n",
              " (('w', 'i'), 1),\n",
              " (('i', 'i'), 1),\n",
              " (('F', 'r'), 1),\n",
              " (('f', 'l'), 1),\n",
              " (('f', ','), 1),\n",
              " (('e', \"'\"), 1),\n",
              " (('y', 'l'), 1),\n",
              " (('c', 'l'), 1),\n",
              " (('l', 'b'), 1),\n",
              " (('e', 'r'), 1),\n",
              " (('b', 'a'), 1),\n",
              " (('C', 'u'), 1),\n",
              " (('t', 'd'), 1),\n",
              " (('i', ','), 1),\n",
              " (('\"', 'h'), 1),\n",
              " (('O', ','), 1),\n",
              " (('h', \"'\"), 1),\n",
              " (('m', 'i'), 1),\n",
              " (('a', 'n'), 1),\n",
              " (('r', 'a'), 1),\n",
              " (('e', 'm'), 1),\n",
              " (('a', '\"'), 1),\n",
              " (('W', 'l'), 1),\n",
              " (('l', ','), 1),\n",
              " (('a', \"'\"), 1),\n",
              " (('w', 'a'), 1),\n",
              " (('w', 'e'), 1),\n",
              " (('j', 'a'), 1),\n",
              " (('l', 'u'), 1),\n",
              " (('u', ','), 1),\n",
              " (('n', 'u'), 1),\n",
              " (('\"', 't'), 1),\n",
              " (('I', \"'\"), 1),\n",
              " (('i', '-'), 1),\n",
              " (('p', 'h'), 1),\n",
              " (('-', 'o'), 1),\n",
              " (('p', 'p'), 1),\n",
              " (('c', 'u'), 1),\n",
              " (('f', 'u'), 1),\n",
              " (('o', 'n'), 1),\n",
              " (('u', 'd'), 1),\n",
              " (('h', 'l'), 1),\n",
              " (('l', 'a'), 1),\n",
              " (('W', 't'), 1),\n",
              " (('c', ','), 1),\n",
              " (('s', 'o'), 1),\n",
              " (('h', 'c'), 1),\n",
              " (('r', 'p'), 1),\n",
              " (('w', 't'), 1),\n",
              " (('D', 'c'), 1),\n",
              " (('T', 'r'), 1),\n",
              " (('r', 'w'), 1),\n",
              " (('\"', 'o'), 1),\n",
              " (('L', 's'), 1),\n",
              " (('o', 'r'), 1),\n",
              " (('u', 's'), 1),\n",
              " (('r', 'e'), 1),\n",
              " (('s', 'l'), 1),\n",
              " (('l', '\"'), 1),\n",
              " (('l', 's'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char = sorted(list(set(words)))"
      ],
      "metadata": {
        "id": "sWqoBOBxH0hl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the training data\n",
        "\n",
        "string2integer = {ch: i for i, ch in enumerate(chars)}\n",
        "print(string2integer)\n",
        "\n",
        "integer2string = {i:ch for ch,i in string2integer.items()}\n",
        "encode = lambda s: [string2integer[c] for c in s]\n",
        "print(encode)\n",
        "\n",
        "decode = lambda l: ''.join([integer2string[i] for i in l])\n",
        "print(decode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEcBOKFlHKLR",
        "outputId": "385d5128-d844-4838-ca71-0cdaa1223c4e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\"': 0, '\"Hey': 1, '\"It\\'s': 2, '\"Lose': 3, '\"Oh,': 4, \"'Cause\": 5, \"'cause\": 6, \"'em\": 7, '(J.J.': 8, 'Doc': 9, 'Fab,': 10, 'Fad)': 11, 'For': 12, 'How': 13, 'I': 14, \"I'm\": 15, \"I'ma\": 16, 'Innovative': 17, 'J': 18, 'Lyrics': 19, 'Never': 20, 'Ray': 21, 'So': 22, 'The': 23, 'Throw': 24, 'Uh,': 25, 'Well,': 26, 'What': 27, 'With': 28, 'You': 29, 'Yourself\"': 30, 'a': 31, 'and': 32, 'anything': 33, 'are': 34, \"assumin'\": 35, 'at': 36, 'audience': 37, 'be': 38, 'can': 39, 'celebrating': 40, \"comin'\": 41, 'confuse': 42, 'day': 43, 'day,': 44, 'demonstrating': 45, 'devastating,': 46, 'do': 47, 'dooma-lumma,': 48, 'elevating': 49, 'elevator': 50, 'ever': 51, 'fading,': 52, 'feeling': 53, 'fell': 54, 'forever': 55, 'found': 56, 'fuse': 57, 'get': 58, 'give': 59, 'glue': 60, 'gotta': 61, 'haters': 62, \"he's\": 63, 'hella': 64, 'hip-hop,': 65, 'human': 66, 'is': 67, 'it': 68, \"it'll\": 69, \"it's\": 70, 'jealous,': 71, 'kill': 72, 'know': 73, 'levitating': 74, 'like': 75, 'lose': 76, 'made': 77, 'mainstream\"': 78, 'make': 79, 'me,': 80, 'more': 81, \"motherfuckin'\": 82, 'motivated': 83, 'music': 84, 'music,': 85, 'next': 86, 'not': 87, 'of': 88, 'off': 89, 'off,': 90, 'on': 91, 'pop,': 92, 'radio': 93, 'rap': 94, \"ricochetin'\": 95, 'rock,': 96, 'rubber': 97, 'say': 98, 'shock': 99, 'so': 100, 'speed': 101, 'station': 102, 'straight': 103, 'summa-lumma,': 104, 'superhuman?': 105, 'supersonic': 106, 'than': 107, 'that': 108, \"that's\": 109, 'the': 110, 'they': 111, \"they'll\": 112, 'through': 113, 'to': 114, 'too': 115, 'very': 116, 'waiting': 117, 'way': 118, 'went': 119, 'what': 120, 'when': 121, 'with': 122, 'you': 123, 'you!\"': 124}\n",
            "<function <lambda> at 0x7fd5011e5f70>\n",
            "<function <lambda> at 0x7fd5011e5ca0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(words), dtype = torch.long)\n",
        "# print(data)\n",
        "n = int(0.4 * len(words))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMPkvDxvMP3N",
        "outputId": "104aa32f-ed6f-4d0a-f7b7-2295b04986e6"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 32,  15,  46,  81, 107,  51,  45,  13, 114,  59,  31,  82,  37,  31,\n",
            "         53,  75,  70,  74,  20,  52,  32,  14,  73, 110,  62,  34,  55, 117,\n",
            "         12, 110,  43, 108, 111,  39,  98,  14,  54,  90, 112,  38,  40,   5,\n",
            "         14,  73, 110, 118, 114,  58,   7,  83,  14,  79,  49,  85, 123,  79,\n",
            "         50,  84,   4,  63, 115,  78,  26, 109, 120, 111,  47, 121, 111,  58,\n",
            "         71, 111,  42,  68,   2,  87,  65,  70,  92,   0,   6,  14,  56,  31,\n",
            "         64, 118, 114,  57,  68,  28,  96,  99,  94, 122,   9,  24,  91,   3,\n",
            "         30,  32,  79,   7,  76,  68])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Z3SdwnFz3d8L",
        "outputId": "5982bdde-cc3a-46c7-a0cc-b66f858dd320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-15b9e367c769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (tuple, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2integer = {ch: i for i, ch in enumerate(char)}\n",
        "print(string2integer)\n",
        "\n",
        "res = dict(enumerate(words))\n",
        "print(res)\n",
        "keyList = [key for key in res]\n",
        "print(keyList)\n",
        "l = len(keyList)\n",
        "l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nS-JjGF9o9x",
        "outputId": "2939a295-74f7-4c8f-f3f7-e0a5c22e6770"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\"': 0, '\"Hey': 1, '\"It\\'s': 2, '\"Lose': 3, '\"Oh,': 4, \"'Cause\": 5, \"'cause\": 6, \"'em\": 7, '(J.J.': 8, 'Doc': 9, 'Fab,': 10, 'Fad)': 11, 'For': 12, 'How': 13, 'I': 14, \"I'm\": 15, \"I'ma\": 16, 'Innovative': 17, 'J': 18, 'Lyrics': 19, 'Never': 20, 'Ray': 21, 'So': 22, 'The': 23, 'Throw': 24, 'Uh,': 25, 'Well,': 26, 'What': 27, 'With': 28, 'You': 29, 'Yourself\"': 30, 'a': 31, 'and': 32, 'anything': 33, 'are': 34, \"assumin'\": 35, 'at': 36, 'audience': 37, 'be': 38, 'can': 39, 'celebrating': 40, \"comin'\": 41, 'confuse': 42, 'day': 43, 'day,': 44, 'demonstrating': 45, 'devastating,': 46, 'do': 47, 'dooma-lumma,': 48, 'elevating': 49, 'elevator': 50, 'ever': 51, 'fading,': 52, 'feeling': 53, 'fell': 54, 'forever': 55, 'found': 56, 'fuse': 57, 'get': 58, 'give': 59, 'glue': 60, 'gotta': 61, 'haters': 62, \"he's\": 63, 'hella': 64, 'hip-hop,': 65, 'human': 66, 'is': 67, 'it': 68, \"it'll\": 69, \"it's\": 70, 'jealous,': 71, 'kill': 72, 'know': 73, 'levitating': 74, 'like': 75, 'lose': 76, 'made': 77, 'mainstream\"': 78, 'make': 79, 'me,': 80, 'more': 81, \"motherfuckin'\": 82, 'motivated': 83, 'music': 84, 'music,': 85, 'next': 86, 'not': 87, 'of': 88, 'off': 89, 'off,': 90, 'on': 91, 'pop,': 92, 'radio': 93, 'rap': 94, \"ricochetin'\": 95, 'rock,': 96, 'rubber': 97, 'say': 98, 'shock': 99, 'so': 100, 'speed': 101, 'station': 102, 'straight': 103, 'summa-lumma,': 104, 'superhuman?': 105, 'supersonic': 106, 'than': 107, 'that': 108, \"that's\": 109, 'the': 110, 'they': 111, \"they'll\": 112, 'through': 113, 'to': 114, 'too': 115, 'very': 116, 'waiting': 117, 'way': 118, 'went': 119, 'what': 120, 'when': 121, 'with': 122, 'you': 123, 'you!\"': 124}\n",
            "{0: 'So', 1: 'Ray', 2: 'J', 3: 'went', 4: 'straight', 5: 'to', 6: 'the', 7: 'radio', 8: 'station', 9: 'The', 10: 'very', 11: 'next', 12: 'day,', 13: '\"Hey', 14: 'Fab,', 15: \"I'ma\", 16: 'kill', 17: 'you!\"', 18: 'Lyrics', 19: \"comin'\", 20: 'at', 21: 'you', 22: 'at', 23: 'supersonic', 24: 'speed', 25: '(J.J.', 26: 'Fad)', 27: 'Uh,', 28: 'summa-lumma,', 29: 'dooma-lumma,', 30: 'you', 31: \"assumin'\", 32: \"I'm\", 33: 'a', 34: 'human', 35: 'What', 36: 'I', 37: 'gotta', 38: 'do', 39: 'to', 40: 'get', 41: 'it', 42: 'through', 43: 'to', 44: 'you', 45: \"I'm\", 46: 'superhuman?', 47: 'Innovative', 48: 'and', 49: \"I'm\", 50: 'made', 51: 'of', 52: 'rubber', 53: 'so', 54: 'that', 55: 'anything', 56: 'You', 57: 'say', 58: 'is', 59: \"ricochetin'\", 60: 'off', 61: 'of', 62: 'me,', 63: 'and', 64: \"it'll\", 65: 'glue', 66: 'to', 67: 'you', 68: 'and', 69: \"I'm\", 70: 'devastating,', 71: 'more', 72: 'than', 73: 'ever', 74: 'demonstrating', 75: 'How', 76: 'to', 77: 'give', 78: 'a', 79: \"motherfuckin'\", 80: 'audience', 81: 'a', 82: 'feeling', 83: 'like', 84: \"it's\", 85: 'levitating', 86: 'Never', 87: 'fading,', 88: 'and', 89: 'I', 90: 'know', 91: 'the', 92: 'haters', 93: 'are', 94: 'forever', 95: 'waiting', 96: 'For', 97: 'the', 98: 'day', 99: 'that', 100: 'they', 101: 'can', 102: 'say', 103: 'I', 104: 'fell', 105: 'off,', 106: \"they'll\", 107: 'be', 108: 'celebrating', 109: \"'Cause\", 110: 'I', 111: 'know', 112: 'the', 113: 'way', 114: 'to', 115: 'get', 116: \"'em\", 117: 'motivated', 118: 'I', 119: 'make', 120: 'elevating', 121: 'music,', 122: 'you', 123: 'make', 124: 'elevator', 125: 'music', 126: '\"Oh,', 127: \"he's\", 128: 'too', 129: 'mainstream\"', 130: 'Well,', 131: \"that's\", 132: 'what', 133: 'they', 134: 'do', 135: 'when', 136: 'they', 137: 'get', 138: 'jealous,', 139: 'they', 140: 'confuse', 141: 'it', 142: '\"It\\'s', 143: 'not', 144: 'hip-hop,', 145: \"it's\", 146: 'pop,', 147: '\"', 148: \"'cause\", 149: 'I', 150: 'found', 151: 'a', 152: 'hella', 153: 'way', 154: 'to', 155: 'fuse', 156: 'it', 157: 'With', 158: 'rock,', 159: 'shock', 160: 'rap', 161: 'with', 162: 'Doc', 163: 'Throw', 164: 'on', 165: '\"Lose', 166: 'Yourself\"', 167: 'and', 168: 'make', 169: \"'em\", 170: 'lose', 171: 'it'}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled dot product attention\n",
        "# 3 matrices, Q -> query matrix\n",
        "# K -> Key matrix\n",
        "# V -> value matrix\n",
        "# T is the length of the sequence\n",
        "import math\n",
        "import numpy as np \n",
        "import torch.nn.functional  as F\n",
        "import torch\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
        "    attn_logits = attn_logits / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
        "    attention = F.softmax(attn_logits, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention"
      ],
      "metadata": {
        "id": "aFiuKJk29oTJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dk and Dv\n",
        " are the hidden dimensionality for queries/keys and values respectively"
      ],
      "metadata": {
        "id": "py-vXvCwGjry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "chars = sorted(list(set(words)))\n",
        "# print(chars)\n",
        "size = len(chars) # sequence length\n",
        "# print(size)\n",
        "\n",
        "\n",
        "d_k = 2\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "q = torch.randn(size, d_k)\n",
        "\n",
        "#q = torch.randn(size, d_k).detach().requires_grad_(True)\n",
        "\n",
        "\n",
        "k = torch.randn(size, d_k)\n",
        "v = torch.randn(size, d_k)\n",
        "values, attention = scaled_dot_product(q, k, v)\n",
        "# print(\"Q\\n\", q)\n",
        "# print(\"K\\n\", k)\n",
        "# print(\"V\\n\", v)\n",
        "print(\"Values\\n\", values[:5].reshape(1, -1))\n",
        "print(\"Attention\\n\", attention[:5].reshape(1, -1))\n",
        "# p = torch.Tensor(values)\n",
        "# p\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKxcaZJ1FWri",
        "outputId": "aa41b06f-3b55-479d-8a4d-79f01fbf68c6"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values\n",
            " tensor([[-0.0024,  0.0350, -0.0502,  0.0396,  0.0462,  0.0850,  0.0854,  0.1279,\n",
            "          0.0942,  0.0176]])\n",
            "Attention\n",
            " tensor([[0.0082, 0.0072, 0.0058, 0.0073, 0.0079, 0.0100, 0.0100, 0.0078, 0.0066,\n",
            "         0.0067, 0.0076, 0.0076, 0.0064, 0.0107, 0.0067, 0.0085, 0.0071, 0.0081,\n",
            "         0.0073, 0.0090, 0.0070, 0.0065, 0.0071, 0.0062, 0.0083, 0.0093, 0.0084,\n",
            "         0.0106, 0.0094, 0.0092, 0.0097, 0.0066, 0.0079, 0.0071, 0.0103, 0.0086,\n",
            "         0.0114, 0.0071, 0.0067, 0.0075, 0.0074, 0.0101, 0.0089, 0.0077, 0.0071,\n",
            "         0.0078, 0.0079, 0.0074, 0.0084, 0.0079, 0.0067, 0.0083, 0.0083, 0.0068,\n",
            "         0.0084, 0.0078, 0.0060, 0.0077, 0.0079, 0.0081, 0.0072, 0.0071, 0.0091,\n",
            "         0.0077, 0.0090, 0.0085, 0.0091, 0.0080, 0.0077, 0.0074, 0.0088, 0.0093,\n",
            "         0.0098, 0.0063, 0.0087, 0.0078, 0.0071, 0.0080, 0.0076, 0.0093, 0.0088,\n",
            "         0.0073, 0.0080, 0.0063, 0.0082, 0.0078, 0.0072, 0.0103, 0.0080, 0.0086,\n",
            "         0.0073, 0.0081, 0.0085, 0.0071, 0.0075, 0.0063, 0.0082, 0.0066, 0.0073,\n",
            "         0.0088, 0.0082, 0.0085, 0.0069, 0.0080, 0.0072, 0.0072, 0.0082, 0.0087,\n",
            "         0.0091, 0.0068, 0.0091, 0.0095, 0.0080, 0.0081, 0.0097, 0.0071, 0.0092,\n",
            "         0.0108, 0.0065, 0.0077, 0.0061, 0.0077, 0.0081, 0.0072, 0.0083, 0.0006,\n",
            "         0.0022, 0.0031, 0.0037, 0.0079, 0.0037, 0.0046, 0.0194, 0.0042, 0.0142,\n",
            "         0.0233, 0.0032, 0.0034, 0.0057, 0.0051, 0.0103, 0.0059, 0.0082, 0.0032,\n",
            "         0.0163, 0.0052, 0.0029, 0.0105, 0.0038, 0.0032, 0.0024, 0.0037, 0.0040,\n",
            "         0.0045, 0.0044, 0.0021, 0.0088, 0.0168, 0.0117, 0.0066, 0.0262, 0.0109,\n",
            "         0.0033, 0.0033, 0.0112, 0.0046, 0.0169, 0.0054, 0.0024, 0.0020, 0.0077,\n",
            "         0.0186, 0.0031, 0.0101, 0.0056, 0.0092, 0.0229, 0.0073, 0.0061, 0.0036,\n",
            "         0.0041, 0.0461, 0.0045, 0.0030, 0.0061, 0.0060, 0.0080, 0.0034, 0.0108,\n",
            "         0.0140, 0.0055, 0.0124, 0.0057, 0.0085, 0.0017, 0.0203, 0.0078, 0.0082,\n",
            "         0.0043, 0.0081, 0.0027, 0.0058, 0.0060, 0.0035, 0.0143, 0.0022, 0.0013,\n",
            "         0.0042, 0.0039, 0.0093, 0.0092, 0.0133, 0.0033, 0.0148, 0.0057, 0.0032,\n",
            "         0.0073, 0.0051, 0.0062, 0.0057, 0.0069, 0.0052, 0.0079, 0.0071, 0.0160,\n",
            "         0.0160, 0.0126, 0.0064, 0.0064, 0.0124, 0.0047, 0.0092, 0.0064, 0.0116,\n",
            "         0.0023, 0.0069, 0.0069, 0.0016, 0.0043, 0.0077, 0.0056, 0.0079, 0.0055,\n",
            "         0.0100, 0.0073, 0.0054, 0.0285, 0.0106, 0.0095, 0.0162, 0.0147, 0.0073,\n",
            "         0.0035, 0.0066, 0.0069, 0.0166, 0.0159, 0.0052, 0.0047, 0.0037, 0.0046,\n",
            "         0.0075, 0.0045, 0.0181, 0.0048, 0.0080, 0.0053, 0.0072, 0.0069, 0.0083,\n",
            "         0.0054, 0.0049, 0.0046, 0.0041, 0.0100, 0.0148, 0.0099, 0.0193, 0.0131,\n",
            "         0.0124, 0.0174, 0.0038, 0.0056, 0.0045, 0.0158, 0.0064, 0.0186, 0.0061,\n",
            "         0.0053, 0.0054, 0.0065, 0.0115, 0.0107, 0.0085, 0.0072, 0.0067, 0.0054,\n",
            "         0.0072, 0.0077, 0.0074, 0.0041, 0.0060, 0.0079, 0.0047, 0.0099, 0.0077,\n",
            "         0.0020, 0.0074, 0.0088, 0.0077, 0.0054, 0.0049, 0.0128, 0.0059, 0.0086,\n",
            "         0.0092, 0.0091, 0.0076, 0.0063, 0.0083, 0.0074, 0.0111, 0.0127, 0.0041,\n",
            "         0.0091, 0.0086, 0.0054, 0.0076, 0.0074, 0.0096, 0.0130, 0.0087, 0.0083,\n",
            "         0.0041, 0.0074, 0.0064, 0.0045, 0.0185, 0.0060, 0.0094, 0.0068, 0.0076,\n",
            "         0.0094, 0.0053, 0.0065, 0.0036, 0.0085, 0.0041, 0.0056, 0.0078, 0.0063,\n",
            "         0.0076, 0.0047, 0.0074, 0.0046, 0.0058, 0.0074, 0.0097, 0.0093, 0.0061,\n",
            "         0.0106, 0.0123, 0.0106, 0.0085, 0.0127, 0.0055, 0.0107, 0.0186, 0.0036,\n",
            "         0.0065, 0.0035, 0.0045, 0.0068, 0.0050, 0.0066, 0.0198, 0.0066, 0.0022,\n",
            "         0.0056, 0.0059, 0.0226, 0.0209, 0.0037, 0.0033, 0.0022, 0.0031, 0.0069,\n",
            "         0.0032, 0.0255, 0.0034, 0.0073, 0.0040, 0.0062, 0.0060, 0.0077, 0.0041,\n",
            "         0.0036, 0.0031, 0.0027, 0.0105, 0.0192, 0.0103, 0.0284, 0.0156, 0.0145,\n",
            "         0.0246, 0.0024, 0.0042, 0.0030, 0.0207, 0.0051, 0.0260, 0.0051, 0.0040,\n",
            "         0.0041, 0.0054, 0.0125, 0.0115, 0.0084, 0.0065, 0.0056, 0.0040, 0.0065,\n",
            "         0.0069, 0.0066, 0.0026, 0.0046, 0.0073, 0.0034, 0.0103, 0.0071, 0.0008,\n",
            "         0.0066, 0.0088, 0.0070, 0.0041, 0.0035, 0.0152, 0.0046, 0.0080, 0.0092,\n",
            "         0.0088, 0.0069, 0.0051, 0.0081, 0.0064, 0.0120, 0.0148, 0.0027, 0.0090,\n",
            "         0.0084, 0.0041, 0.0069, 0.0067, 0.0094, 0.0158, 0.0087, 0.0079, 0.0027,\n",
            "         0.0065, 0.0052, 0.0030, 0.0267, 0.0046, 0.0095, 0.0059, 0.0068, 0.0095,\n",
            "         0.0040, 0.0054, 0.0022, 0.0082, 0.0027, 0.0043, 0.0069, 0.0051, 0.0067,\n",
            "         0.0033, 0.0066, 0.0032, 0.0046, 0.0065, 0.0099, 0.0091, 0.0050, 0.0112,\n",
            "         0.0141, 0.0118, 0.0082, 0.0148, 0.0042, 0.0115, 0.0266, 0.0022, 0.0054,\n",
            "         0.0021, 0.0030, 0.0058, 0.0036, 0.0054, 0.1001, 0.0209, 0.0148, 0.0107,\n",
            "         0.0040, 0.0091, 0.0071, 0.0013, 0.0097, 0.0021, 0.0011, 0.0128, 0.0126,\n",
            "         0.0053, 0.0075, 0.0028, 0.0061, 0.0038, 0.0128, 0.0016, 0.0071, 0.0152,\n",
            "         0.0030, 0.0111, 0.0119, 0.0166, 0.0102, 0.0081, 0.0074, 0.0078, 0.0186,\n",
            "         0.0038, 0.0016, 0.0026, 0.0045, 0.0009, 0.0023, 0.0126, 0.0127, 0.0027,\n",
            "         0.0081, 0.0014, 0.0061, 0.0177, 0.0237, 0.0042, 0.0014, 0.0132, 0.0029,\n",
            "         0.0062, 0.0036, 0.0011, 0.0044, 0.0059, 0.0103, 0.0093, 0.0005, 0.0083,\n",
            "         0.0135, 0.0055, 0.0059, 0.0042, 0.0108, 0.0028, 0.0019, 0.0062, 0.0022,\n",
            "         0.0060, 0.0037, 0.0290, 0.0012, 0.0038, 0.0035, 0.0096, 0.0037, 0.0157,\n",
            "         0.0062, 0.0056, 0.0114, 0.0018, 0.0183, 0.0407, 0.0089, 0.0107, 0.0032,\n",
            "         0.0034, 0.0022, 0.0107, 0.0019, 0.0058, 0.0127, 0.0044, 0.0067, 0.0057,\n",
            "         0.0061, 0.0053, 0.0066, 0.0043, 0.0048, 0.0016, 0.0017, 0.0022, 0.0056,\n",
            "         0.0052, 0.0024, 0.0081, 0.0033, 0.0050, 0.0023, 0.0202, 0.0045, 0.0043,\n",
            "         0.0302, 0.0086, 0.0037, 0.0065, 0.0037, 0.0054, 0.0033, 0.0045, 0.0074,\n",
            "         0.0008, 0.0028, 0.0034, 0.0016]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b = sorted(list(set(values[:n])))\n",
        "\n",
        "# d  = torch.stack(b)\n",
        "# d\n",
        "# g = sorted(list(set(attention[:5])))\n"
      ],
      "metadata": {
        "id": "LuFscL68but-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  Tensor ops tbc"
      ],
      "metadata": {
        "id": "dR9-u68lEr07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((40, 40), dtype=torch.int32)\n"
      ],
      "metadata": {
        "id": "EtKi2zNbrpTr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "# chars\n",
        "\n",
        "string2integer = {ch: i for i, ch in enumerate(chars)}\n",
        "# print(string2integer)\n",
        "\n",
        "integer2string = {i:ch for ch,i in string2integer.items()}\n",
        "# print(integer2string)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G7r5J_4BrtYs"
      },
      "execution_count": 194,
      "outputs": []
    }
  ]
}