{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKVODJFxAS67Waboe7TDa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadip1995/language-models/blob/main/Notebook/Multi_head_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-iyjhxM5BKS",
        "outputId": "e40d3c82-3446-42fc-cb23-8248cf615398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['So',\n",
              " 'Ray',\n",
              " 'J',\n",
              " 'went',\n",
              " 'straight',\n",
              " 'to',\n",
              " 'the',\n",
              " 'radio',\n",
              " 'station',\n",
              " 'The',\n",
              " 'very',\n",
              " 'next',\n",
              " 'day,',\n",
              " '\"Hey',\n",
              " 'Fab,',\n",
              " \"I'ma\",\n",
              " 'kill',\n",
              " 'you!\"',\n",
              " 'Lyrics',\n",
              " \"comin'\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "words = open('/content/text.txt', 'r').read().split()\n",
        "words[:20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "chars = sorted(list(set(words)))\n",
        "string2integer = {ch: i for i, ch in enumerate(chars)}\n",
        "print(string2integer)\n",
        "\n",
        "integer2string = {i:ch for ch,i in string2integer.items()}\n",
        "encode = lambda s: [string2integer[c] for c in s]\n",
        "print(encode)\n",
        "\n",
        "decode = lambda l: ''.join([integer2string[i] for i in l])\n",
        "print(decode)\n",
        "\n",
        "data = torch.tensor(encode(words), dtype = torch.long)\n",
        "print(data)\n",
        "data.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuriIPRQ5WA9",
        "outputId": "5a26cd88-6526-4791-858a-1d007bd89884"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\"': 0, '\"Hey': 1, '\"It\\'s': 2, '\"Lose': 3, '\"Oh,': 4, \"'Cause\": 5, \"'cause\": 6, \"'em\": 7, '(J.J.': 8, 'Doc': 9, 'Fab,': 10, 'Fad)': 11, 'For': 12, 'How': 13, 'I': 14, \"I'm\": 15, \"I'ma\": 16, 'Innovative': 17, 'J': 18, 'Lyrics': 19, 'Never': 20, 'Ray': 21, 'So': 22, 'The': 23, 'Throw': 24, 'Uh,': 25, 'Well,': 26, 'What': 27, 'With': 28, 'You': 29, 'Yourself\"': 30, 'a': 31, 'and': 32, 'anything': 33, 'are': 34, \"assumin'\": 35, 'at': 36, 'audience': 37, 'be': 38, 'can': 39, 'celebrating': 40, \"comin'\": 41, 'confuse': 42, 'day': 43, 'day,': 44, 'demonstrating': 45, 'devastating,': 46, 'do': 47, 'dooma-lumma,': 48, 'elevating': 49, 'elevator': 50, 'ever': 51, 'fading,': 52, 'feeling': 53, 'fell': 54, 'forever': 55, 'found': 56, 'fuse': 57, 'get': 58, 'give': 59, 'glue': 60, 'gotta': 61, 'haters': 62, \"he's\": 63, 'hella': 64, 'hip-hop,': 65, 'human': 66, 'is': 67, 'it': 68, \"it'll\": 69, \"it's\": 70, 'jealous,': 71, 'kill': 72, 'know': 73, 'levitating': 74, 'like': 75, 'lose': 76, 'made': 77, 'mainstream\"': 78, 'make': 79, 'me,': 80, 'more': 81, \"motherfuckin'\": 82, 'motivated': 83, 'music': 84, 'music,': 85, 'next': 86, 'not': 87, 'of': 88, 'off': 89, 'off,': 90, 'on': 91, 'pop,': 92, 'radio': 93, 'rap': 94, \"ricochetin'\": 95, 'rock,': 96, 'rubber': 97, 'say': 98, 'shock': 99, 'so': 100, 'speed': 101, 'station': 102, 'straight': 103, 'summa-lumma,': 104, 'superhuman?': 105, 'supersonic': 106, 'than': 107, 'that': 108, \"that's\": 109, 'the': 110, 'they': 111, \"they'll\": 112, 'through': 113, 'to': 114, 'too': 115, 'very': 116, 'waiting': 117, 'way': 118, 'went': 119, 'what': 120, 'when': 121, 'with': 122, 'you': 123, 'you!\"': 124}\n",
            "<function <lambda> at 0x7f6b39d22dc0>\n",
            "<function <lambda> at 0x7f6b39d22f70>\n",
            "tensor([ 22,  21,  18, 119, 103, 114, 110,  93, 102,  23, 116,  86,  44,   1,\n",
            "         10,  16,  72, 124,  19,  41,  36, 123,  36, 106, 101,   8,  11,  25,\n",
            "        104,  48, 123,  35,  15,  31,  66,  27,  14,  61,  47, 114,  58,  68,\n",
            "        113, 114, 123,  15, 105,  17,  32,  15,  77,  88,  97, 100, 108,  33,\n",
            "         29,  98,  67,  95,  89,  88,  80,  32,  69,  60, 114, 123,  32,  15,\n",
            "         46,  81, 107,  51,  45,  13, 114,  59,  31,  82,  37,  31,  53,  75,\n",
            "         70,  74,  20,  52,  32,  14,  73, 110,  62,  34,  55, 117,  12, 110,\n",
            "         43, 108, 111,  39,  98,  14,  54,  90, 112,  38,  40,   5,  14,  73,\n",
            "        110, 118, 114,  58,   7,  83,  14,  79,  49,  85, 123,  79,  50,  84,\n",
            "          4,  63, 115,  78,  26, 109, 120, 111,  47, 121, 111,  58,  71, 111,\n",
            "         42,  68,   2,  87,  65,  70,  92,   0,   6,  14,  56,  31,  64, 118,\n",
            "        114,  57,  68,  28,  96,  99,  94, 122,   9,  24,  91,   3,  30,  32,\n",
            "         79,   7,  76,  68])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([172])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "block_size = 64\n",
        "batch_size = 512\n",
        "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "ix.size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3Y9VdIx5h5k",
        "outputId": "6c2b4dee-0777-4a1a-d941-a64796273701"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "\n",
        "d_k = 512\n",
        "\n",
        "token_emb = nn.Embedding(vocab_size, d_k)\n",
        "token_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSS2glS2Pbv9",
        "outputId": "8929fe09-3ee9-4622-d675-b57e7f8e41ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(125, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "x.shape\n",
        "# d = x.float()\n",
        "# d\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9X-oqv75k4U",
        "outputId": "0b93e02b-a178-404f-b6cf-5789f1e99a92"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeds = token_emb(x)\n",
        "input_embeds.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx-6ks-EPs9E",
        "outputId": "1ef68d26-fd1a-4633-a715-1de4990e4241"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# p = x.transpose(-2, 1)\n",
        "# p.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1y83mbKHM5c",
        "outputId": "3b1a157d-4941-4aad-e11f-e5c19c82a9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np \n",
        "import torch.nn.functional  as F\n",
        "import torch\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "def scaled_dot_product(query, key, value):\n",
        "  dim_k = query.size(-1)\n",
        "  scores = torch.bmm(query, key.transpose(-2, -1)) / sqrt(dim_k)\n",
        "  weights = F.softmax(scores, dim = -1)\n",
        "  return torch.bmm(weights, value)\n",
        "  \n"
      ],
      "metadata": {
        "id": "MHWCNqg0egmK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size = 64\n",
        "# dim_k = 512\n",
        "# key = torch.randn(batch_size, size, dim_k)\n",
        "# value = torch.randn(batch_size, size, dim_k) \n",
        "# query = torch.randn(batch_size, size, dim_k)\n",
        "\n",
        "key = input_embeds\n",
        "query = input_embeds\n",
        "value = input_embeds\n",
        "\n",
        "sdp = scaled_dot_product(query, key, value)\n",
        "sdp.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXYuihMcVqQL",
        "outputId": "4b96778e-a7a4-47c5-99a6-dc816665a2f5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# chars = sorted(list(set(words)))\n",
        "# # print(chars)\n",
        "# size = len(chars) # sequence length\n",
        "# # print(size)\n",
        "\n",
        "# torch.manual_seed(1337)\n",
        "\n",
        "\n",
        "\n",
        "# key , value, query = input_embeds\n",
        "\n",
        "# # key = torch.randn(batch_size, size, dim_k)\n",
        "# # value = torch.randn(batch_size, size, dim_k) \n",
        "# # query = torch.randn(batch_size, size, dim_k)\n",
        "\n",
        "\n",
        "\n",
        "# sdp = scaled_dot_product_attention(query, key, value)\n",
        "# sdp.size()"
      ],
      "metadata": {
        "id": "D1zKRv0NiPph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## A single attention head\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embedded_dim, head_dim):\n",
        "    super().__init__()\n",
        "    self.q = nn.Linear(embedded_dim, head_dim)\n",
        "    self.k = nn.Linear(embedded_dim,  head_dim)\n",
        "    self.v = nn.Linear(embedded_dim,  head_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    attention_outputs = scaled_dot_product(self.q(x), self.k(x), self.v(x))\n",
        "    \n",
        "\n",
        "    return attention_outputs\n",
        "    "
      ],
      "metadata": {
        "id": "ba0pIBp_wn10"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi headed attention\n",
        "\n",
        "Having many heads allows the model to focus on different parts of the sentences. The softmax on one head tends to focus on one aspect of similarity. For example subject verb interaction."
      ],
      "metadata": {
        "id": "60CoxkPnl7nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_dim = embedding dimensions\n",
        "# num_heads  = number of heads \n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embedded_dim, num_heads):\n",
        "    super().__init__()\n",
        "    self.embedded_dim = embedded_dim\n",
        "    self.num_heads = num_heads\n",
        "    head_dim = embedded_dim // num_heads \n",
        "\n",
        "    self.heads = nn.ModuleList([AttentionHead(embedded_dim, head_dim) for _ in range(num_heads)])\n",
        "    self.output_linear = nn.Linear(embedded_dim, embedded_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
        "    \n",
        "    out = self.output_linear(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "pI0uLzziwwIj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_attention = MultiHeadAttention(512, 8)\n",
        "# multihead_attention\n",
        "\n",
        "attention_outputs =  multihead_attention(input_embeds)\n",
        "attention_outputs.size()"
      ],
      "metadata": {
        "id": "GTfXMZx4xGdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302441e7-521c-460f-aee5-578a093b6f28"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ⬆ A discrepancy in shape is occuring in the above snippet. Will try to fix it.\n",
        "\n",
        "Note:-  Discrepancy has been solved.\n",
        "\n",
        "An alternative implementation of Multi headed attention has also been provided.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uy7tHDS2mFG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        \n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = K.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k).float())\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        weights = nn.Softmax(dim=-1)(scores)\n",
        "        output = torch.matmul(weights, V)\n",
        "        return output\n",
        "        \n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        \n",
        "        \n",
        "        # Apply linear transformation to Q, K, and V\n",
        "        Q = self.W_q(Q)\n",
        "        K = self.W_k(K)\n",
        "        V = self.W_v(V)\n",
        "        \n",
        "        # Split into multiple heads\n",
        "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k)\n",
        "        K = K.view(batch_size, -1, self.num_heads, self.d_k)\n",
        "        V = V.view(batch_size, -1, self.num_heads, self.d_k)\n",
        "        \n",
        "        # Transpose to prepare for matrix multiplication\n",
        "        Q = Q.transpose(1, 2)\n",
        "        K = K.transpose(1, 2)\n",
        "        V = V.transpose(1, 2)\n",
        "        \n",
        "        # Compute attention scores and weights\n",
        "        output = self.scaled_dot_product_attention(Q, K, V, mask=mask)\n",
        "        \n",
        "        # Concatenate the outputs of the multiple heads\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        output = self.W_o(output)\n",
        "        \n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "AVQqRkLydBfB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d_model = 512\n",
        "# num_heads = 8\n",
        "\n",
        "import torch\n",
        "chars = sorted(list(set(words)))\n",
        "# print(chars)\n",
        "seq_len = len(chars) # sequence length\n",
        "\n",
        "\n",
        "\n",
        "Q = input_embeds\n",
        "K = input_embeds\n",
        "V = input_embeds\n",
        "\n",
        "# Q = torch.randn(batch_size, seq_len, d_model)\n",
        "# K = torch.randn(batch_size, seq_len, d_model)\n",
        "# V = torch.randn(batch_size, seq_len, d_model)\n",
        "\n",
        "# Create an instance of the multi-head attention model\n",
        "multihead_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# Pass the input tensors through the model\n",
        "output = multihead_attn(Q, K, V)\n",
        "\n",
        "# The output tensor has shape (batch_size, seq_len, d_model)\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CaB5Zw0a3Ej",
        "outputId": "15dd521a-14fd-4509-d55b-2c71fc47c91e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This one works, for now."
      ],
      "metadata": {
        "id": "N6GfKJpzme1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_dim = embedding dimensions\n",
        "# num_heads  = number of heads \n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embedded_dim, num_heads):\n",
        "    super().__init__()\n",
        "    self.embedded_dim = embedded_dim\n",
        "    self.num_heads = num_heads\n",
        "    head_dim = embedded_dim // num_heads \n",
        "\n",
        "    self.heads = nn.ModuleList([AttentionHead(embedded_dim, head_dim) for _ in range(num_heads)])\n",
        "    self.output_linear = nn.Linear(embedded_dim, embedded_dim)\n",
        "\n",
        "  def forward(self, p):\n",
        "    out = torch.cat([h(p) for h in self.heads], dim = -1)\n",
        "    \n",
        "    out = self.output_linear(out)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "9YHPWifthH2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_attention = MultiHeadAttention(embedded_dim = 512, num_heads = 8)\n",
        "multihead_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzkvfL57heSZ",
        "outputId": "406c8719-c4c1-4281-a701-0eeb5fa9ea05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (heads): ModuleList(\n",
              "    (0): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (1): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (2): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (3): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (4): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (5): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (6): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "    (7): AttentionHead(\n",
              "      (q): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (k): Linear(in_features=512, out_features=64, bias=False)\n",
              "      (v): Linear(in_features=512, out_features=64, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Single headed attention\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SingleAttention(nn.Module):\n",
        "    def __init__(self, embedded_dim):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.embedded_dim = embedded_dim\n",
        "        \n",
        "        self.W_q = nn.Linear(embedded_dim, embedded_dim)\n",
        "        self.W_k = nn.Linear(embedded_dim, embedded_dim)\n",
        "        self.W_v = nn.Linear(embedded_dim, embedded_dim)\n",
        "        self.W_o = nn.Linear(embedded_dim, embedded_dim)\n",
        "        \n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        \n",
        "        \n",
        "        # Apply linear transformation to Q, K, and V\n",
        "        Q = self.W_q(Q)\n",
        "        K = self.W_k(K)\n",
        "        V = self.W_v(V)\n",
        "        \n",
        "        # Compute attention scores and weights\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.embedded_dim).float())\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        weights = nn.Softmax(dim=-1)(scores)\n",
        "        \n",
        "        # Apply attention weights to values\n",
        "        output = torch.matmul(weights, V)\n",
        "        output = self.W_o(output)\n",
        "        \n",
        "        return output\n"
      ],
      "metadata": {
        "id": "-bfLrHoQnFnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "chars = sorted(list(set(words)))\n",
        "# print(chars)\n",
        "seq_len = len(chars) # sequence length\n",
        "embedded_dim = 512\n",
        "\n",
        "\n",
        "# Create some dummy input tensors\n",
        "Q = torch.randn(batch_size, seq_len, embedded_dim)\n",
        "\n",
        "K = torch.randn(batch_size, seq_len, embedded_dim)\n",
        "V = torch.randn(batch_size, seq_len, embedded_dim)\n",
        "\n",
        "# Create an instance of the single attention model\n",
        "single_attn = SingleAttention(embedded_dim)\n",
        "\n",
        "# Pass the input tensors through the model\n",
        "output = single_attn(Q, K, V)\n",
        "output.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIxYtzE8nWhI",
        "outputId": "a5a94f49-51fc-4150-fdf7-f5b4a7db2bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 125, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "554oVPXfwP_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}